import streamlit as st
import os
import asyncio
import uuid
import tempfile
from pathlib import Path
from typing import List, Optional
import json
from dataclasses import dataclass
from datetime import datetime
import httpx
import base64
import io
import fitz  # PyMuPDF
from PIL import Image
from cv_analyzer import CVAnalyzer
from dotenv import load_dotenv
from kafka import KafkaProducer
from kafka.errors import KafkaError, NoBrokersAvailable
import time
import asyncpg

load_dotenv()

@dataclass
class CandidateResult:
    candidate_id: str  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    name: str
    filename: str
    score: int
    reasoning: str
    key_strengths: List[str]
    concerns: List[str]
    cv_summary: str
    interview_questions: List[str]
    email: str
    preferred_contact: str  # –ù–æ–≤–æ–µ –ø–æ–ª–µ –¥–ª—è —Å–ø–æ—Å–æ–±–∞ —Å–≤—è–∑–∏
    cv_text: str

class HRDatabaseClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PostgreSQL –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö HR —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self):
        self.db_url = os.getenv("DATABASE_URL", "postgresql://hr_user:hr_secure_password_2024@postgres_hr:5432/hr_system")
        self.enabled = os.getenv("DATABASE_ENABLED", "true").lower() == "true"
    
    async def save_cv_analysis_results(
        self, 
        request_id: str,
        vacancy_title: str, 
        vacancy_description: str,
        candidates_data: List[dict]
    ) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ CV –≤ –ë–î"""
        if not self.enabled:
            return False
            
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é insert_cv_analysis_data –∏–∑ –ë–î
                result = await conn.fetchval(
                    """
                    SELECT insert_cv_analysis_data($1::UUID, $2, $3, $4::JSONB)
                    """,
                    uuid.UUID(request_id) if isinstance(request_id, str) else request_id,
                    vacancy_title,
                    vacancy_description,
                    json.dumps(candidates_data)
                )
                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î: {len(candidates_data)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
                return True
            finally:
                await conn.close()
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {str(e)}")
            return False
    
    async def get_request_statistics(self, request_id: str) -> Optional[dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        if not self.enabled:
            return None
            
        try:
            conn = await asyncpg.connect(self.db_url)
            try:
                row = await conn.fetchrow(
                    """
                    SELECT * FROM requests_statistics 
                    WHERE request_id = $1::UUID
                    """,
                    uuid.UUID(request_id)
                )
                if row:
                    return {
                        'vacancy_title': row['vacancy_title'],
                        'total_candidates': row['total_candidates'],
                        'analyzed_candidates': row['analyzed_candidates'],
                        'avg_cv_score': float(row['avg_cv_score']) if row['avg_cv_score'] else 0,
                        'high_suitability': row['high_suitability'],
                        'medium_suitability': row['medium_suitability'],
                        'low_suitability': row['low_suitability']
                    }
                return None
            finally:
                await conn.close()
        except Exception:
            return None

class StreamlitCVAnalyzer:
    def __init__(self):
        self.api_url = os.getenv("OCR_API_URL", "http://api:9001/v1/ocr/process")
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: —É–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏/–ø—Ä–æ–±–µ–ª—ã –∏ –ø–æ–Ω–∏–∂–∞–µ–º —Ä–µ–≥–∏—Å—Ç—Ä
        self.ocr_provider = (os.getenv("OCR_PROVIDER", "api") or "").strip().strip('"').strip("'").lower()  # api | openrouter
        self.openrouter_base = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
        raw_key = os.getenv("OPENROUTER_API_KEY") or os.getenv("OPENAI_API_KEY", "")
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏/–ø—Ä–æ–±–µ–ª—ã –∏–∑ –∫–ª—é—á–∞
        self.openrouter_key = (raw_key or "").strip().strip('"').strip("'")
        self.ocr_openrouter_model = os.getenv(
            "OCR_OPENROUTER_MODEL",
            "meta-llama/llama-3.2-11b-vision-instruct:free",
        )
        # –ê–≤—Ç–æ–ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ OpenRouter, –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π –∫–ª—é—á
        if self.ocr_provider != "openrouter" and self.openrouter_key:
            self.ocr_provider = "openrouter"

        self.cv_analyzer = CVAnalyzer(
            model_name=os.getenv("OPENROUTER_LLM_MODEL", "google/gemma-3-27b-it:free"),
            model_url=os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1"),
        )
        
        # –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –ë–î
        self.db_client = HRDatabaseClient()

        # Kafka config
        self.kafka_bootstrap = os.getenv("KAFKA_BOOTSTRAP_SERVERS", "").strip()
        self.kafka_topic = os.getenv("KAFKA_TOPIC", "").strip()
        self.kafka_connect_max_retries = int(os.getenv("KAFKA_CONNECT_MAX_RETRIES", "8") or 8)
        self.kafka_connect_backoff_seconds = float(os.getenv("KAFKA_CONNECT_BACKOFF_SECONDS", "2") or 2)
        self.kafka_producer = None
        if self.kafka_bootstrap and self.kafka_topic:
            # –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–¥—å—é—Å–µ—Ä (–±–µ–∑ –¥–æ–ª–≥–æ–π –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ UI)
            try:
                self.kafka_producer = self._create_kafka_producer()
            except Exception as e:
                st.warning(f"Kafka –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ: {e}")

    def _build_kafka_config(self) -> dict:
        servers = [s.strip() for s in self.kafka_bootstrap.split(",") if s.strip()]
        cfg = {
            "bootstrap_servers": servers,
            "value_serializer": lambda v: json.dumps(v, ensure_ascii=False).encode("utf-8"),
            "acks": "all",
            "linger_ms": 50,
            "retries": 3,
            "max_in_flight_requests_per_connection": 1,
            "request_timeout_ms": 10000,
            "retry_backoff_ms": 500,
            "metadata_max_age_ms": 30000,
        }
        security_protocol = (os.getenv("KAFKA_SECURITY_PROTOCOL", "") or "").strip()
        if security_protocol:
            cfg["security_protocol"] = security_protocol
        sasl_mechanism = (os.getenv("KAFKA_SASL_MECHANISM", "") or "").strip()
        if sasl_mechanism:
            cfg["sasl_mechanism"] = sasl_mechanism
        sasl_username = os.getenv("KAFKA_SASL_USERNAME")
        sasl_password = os.getenv("KAFKA_SASL_PASSWORD")
        if sasl_username and sasl_password:
            cfg["sasl_plain_username"] = sasl_username
            cfg["sasl_plain_password"] = sasl_password
        ssl_cafile = os.getenv("KAFKA_SSL_CAFILE")
        if ssl_cafile:
            cfg["ssl_cafile"] = ssl_cafile
        return cfg

    def _create_kafka_producer(self) -> KafkaProducer:
        cfg = self._build_kafka_config()
        producer = KafkaProducer(**cfg)
        return producer

    def _ensure_kafka_connected_with_retries(self) -> bool:
        if not (self.kafka_bootstrap and self.kafka_topic):
            return False
        # –ë—ã—Å—Ç—Ä—ã–π —É—Å–ø–µ—à–Ω—ã–π –ø—É—Ç—å
        if self.kafka_producer is not None:
            try:
                if self.kafka_producer.bootstrap_connected():
                    return True
            except Exception:
                self.kafka_producer = None

        attempts = 0
        backoff = max(self.kafka_connect_backoff_seconds, 0.5)
        last_error: Exception | None = None
        while attempts < self.kafka_connect_max_retries:
            attempts += 1
            try:
                self.kafka_producer = self._create_kafka_producer()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö/–±—Ä–æ–∫–µ—Ä–∞
                try:
                    _ = self.kafka_producer.partitions_for(self.kafka_topic)
                except Exception:
                    pass
                if self.kafka_producer.bootstrap_connected():
                    return True
            except (NoBrokersAvailable, KafkaError, Exception) as e:
                last_error = e
                time.sleep(backoff)
                backoff = min(backoff * 2, 30)

        if last_error:
            st.warning(f"Kafka –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {last_error}")
        return False

    async def process_pdf_with_api(self, file_path: str) -> str:
        try:
            async with httpx.AsyncClient() as client:
                with open(file_path, "rb") as f:
                    files = {"files": (Path(file_path).name, f.read(), "application/pdf")}
                    response = await client.post(
                        self.api_url,
                        files=files,
                        data={"output_format": "text"},
                        timeout=60.0
                    )
                
                if response.status_code != 200:
                    st.error(f"API error: {response.text}")
                    return ""
                
                result = response.json()
                return result.get("text", "")
        except Exception as e:
            st.error(f"Error processing PDF with API: {str(e)}")
            return ""

    async def process_pdf_with_openrouter(self, file_path: str) -> str:
        if not self.openrouter_key:
            st.error("–ö–ª—é—á –¥–ª—è OpenRouter –Ω–µ –∑–∞–¥–∞–Ω. –£–∫–∞–∂–∏—Ç–µ OPENROUTER_API_KEY –∏–ª–∏ OPENAI_API_KEY.")
            return ""

        def render_pdf_to_images(pdf_path: str) -> List[Image.Image]:
            images: List[Image.Image] = []
            doc = fitz.open(pdf_path)
            try:
                zoom = 300.0 / 72.0
                mat = fitz.Matrix(zoom, zoom)
                for page in doc:
                    pix = page.get_pixmap(matrix=mat, alpha=False)
                    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                    images.append(img)
            finally:
                doc.close()
            return images

        async def ocr_image(img: Image.Image) -> str:
            buf = io.BytesIO()
            img.save(buf, format="PNG")
            img_bytes = buf.getvalue()
            img_b64 = base64.b64encode(img_bytes).decode("utf-8")

            # –í—Å–µ–≥–¥–∞ —á–∏—Ç–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—ã–∑–æ–≤–∞
            current_ocr_model = os.getenv("OCR_OPENROUTER_MODEL", self.ocr_openrouter_model)
            if not current_ocr_model:
                current_ocr_model = self.ocr_openrouter_model

            payload = {
                "model": current_ocr_model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": (
                                    "Transcribe this page to plain UTF-8 text in Russian if content is Russian. "
                                    "Preserve reading order. Do not add explanations or formatting. Output only the text."
                                ),
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_b64}"
                                },
                            },
                        ],
                    }
                ],
                "temperature": 0,
                "max_tokens": 8000,
            }

            headers = {
                "Authorization": f"Bearer {self.openrouter_key}",
                "Content-Type": "application/json",
                # –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ OpenRouter –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                "HTTP-Referer": os.getenv("OPENROUTER_APP_URL", "http://localhost:8503"),
                "Referer": os.getenv("OPENROUTER_APP_URL", "http://localhost:8503"),
                "X-Title": os.getenv("OPENROUTER_APP_TITLE", "CV Agent"),
            }

            async with httpx.AsyncClient(timeout=60.0) as client:
                resp = await client.post(
                    f"{self.openrouter_base}/chat/completions", json=payload, headers=headers
                )
                if resp.status_code != 200:
                    raise RuntimeError(f"OpenRouter OCR error: {resp.status_code} {resp.text}")
                data = resp.json()
                return (
                    data.get("choices", [{}])[0]
                    .get("message", {})
                    .get("content", "")
                    .strip()
                )

        try:
            images = render_pdf_to_images(file_path)
            text_parts: List[str] = []
            for idx, img in enumerate(images):
                st.write(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {idx + 1}/{len(images)} —á–µ—Ä–µ–∑ OpenRouter‚Ä¶")
                page_text = await ocr_image(img)
                text_parts.append(page_text)
            return "\n\n".join(text_parts)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ OCR —á–µ—Ä–µ–∑ OpenRouter: {e}")
            return ""

    async def process_uploaded_files(self, uploaded_files, job_description: str) -> List[CandidateResult]:
        results = []
        with tempfile.TemporaryDirectory() as temp_dir:
            file_paths = []
            for uploaded_file in uploaded_files:
                unique_suffix = uuid.uuid4().hex[:8]
                safe_name = f"{unique_suffix}_{uploaded_file.name}"
                file_path = os.path.join(temp_dir, safe_name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getvalue())
                file_paths.append((safe_name, file_path))
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            cv_texts = {}
            
            for i, (save_filename, file_path) in enumerate(file_paths):
                status_text.text(f"–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ {Path(file_path).name}...")
                progress_bar.progress((i) / len(file_paths) * 0.6)
                try:
                    if file_path.lower().endswith('.pdf'):
                        if self.ocr_provider == "openrouter":
                            cv_text = await self.process_pdf_with_openrouter(file_path)
                        else:
                            cv_text = await self.process_pdf_with_api(file_path)
                        cv_texts[save_filename] = cv_text
                    else:
                        st.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {Path(file_path).name}")
                        continue
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {Path(file_path).name}: {str(e)}")
                    continue
            
            for i, (filename, cv_text) in enumerate(cv_texts.items()):
                if not cv_text.strip():
                    continue
                status_text.text(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –∏–∑ {filename}...")
                progress_bar.progress(0.6 + (i) / len(cv_texts) * 0.4)
                try:
                    analysis = await self.cv_analyzer.analyze_cv(cv_text, job_description)
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º email
                    candidate_email, preferred_contact = self.extract_contact_info(cv_text)
                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –¥–ª—è –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
                    candidate_id = f"cv_{uuid.uuid4().hex[:12]}"
                    result = CandidateResult(
                        candidate_id=candidate_id,
                        name=analysis.candidate_name,
                        filename=filename,
                        score=analysis.score,
                        reasoning=analysis.reasoning,
                        key_strengths=analysis.key_strengths,
                        concerns=analysis.concerns,
                        cv_summary=analysis.cv_summary,
                        interview_questions=analysis.interview_questions,
                        email=candidate_email,
                        preferred_contact=preferred_contact,
                        cv_text=cv_text,
                    )
                    results.append(result)
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {filename}: {str(e)}")
                    continue
            
            progress_bar.progress(1.0)
            status_text.text("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        return results

    def extract_contact_info(self, cv_text: str) -> tuple[str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–∑—é–º–µ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º email.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (email, preferred_contact_method)
        """
        import re as _re
        
        # 1. –ü–æ–∏—Å–∫ email (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        email_pattern = r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}"
        email_match = _re.search(email_pattern, cv_text)
        email = email_match.group(0) if email_match else ""
        
        if email:
            return email, f"üìß {email}"
        
        # 2. –ü–æ–∏—Å–∫ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ (–µ—Å–ª–∏ –Ω–µ—Ç email)
        phone_patterns = [
            r"\+7[\s\-\(\)]?[\d\s\-\(\)]{10,}",  # +7 —Ñ–æ—Ä–º–∞—Ç
            r"8[\s\-\(\)]?[\d\s\-\(\)]{10,}",    # 8 —Ñ–æ—Ä–º–∞—Ç
            r"\+\d{1,3}[\s\-\(\)]?[\d\s\-\(\)]{7,}",  # –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π
            r"\b\d{3}[\s\-]?\d{3}[\s\-]?\d{4}\b",  # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π
        ]
        
        for pattern in phone_patterns:
            phone_match = _re.search(pattern, cv_text)
            if phone_match:
                phone = _re.sub(r"[\s\-\(\)]", "", phone_match.group(0))
                return "", f"üìû {phone}"
        
        # 3. –ü–æ–∏—Å–∫ Telegram
        telegram_patterns = [
            r"@[\w\d_]+",  # @username
            r"t\.me/[\w\d_]+",  # t.me/username
            r"telegram\.me/[\w\d_]+",  # telegram.me/username
        ]
        
        for pattern in telegram_patterns:
            tg_match = _re.search(pattern, cv_text, _re.IGNORECASE)
            if tg_match:
                tg = tg_match.group(0)
                return "", f"üí¨ Telegram: {tg}"
        
        # 4. –ü–æ–∏—Å–∫ LinkedIn
        linkedin_patterns = [
            r"linkedin\.com/in/[\w\d\-_]+",
            r"linkedin\.com/profile/[\w\d\-_]+",
        ]
        
        for pattern in linkedin_patterns:
            li_match = _re.search(pattern, cv_text, _re.IGNORECASE)
            if li_match:
                li = li_match.group(0)
                return "", f"üíº LinkedIn: {li}"
        
        # 5. Fallback - –ø–æ–∏—Å–∫ –ª—é–±–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ
        contact_keywords = ["–∫–æ–Ω—Ç–∞–∫—Ç", "—Å–≤—è–∑–∞—Ç—å—Å—è", "—Ç–µ–ª–µ—Ñ–æ–Ω", "–ø–æ—á—Ç–∞", "email"]
        lines = cv_text.split('\n')
        
        for line in lines:
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in contact_keywords):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –∫–æ–Ω—Ç–∞–∫—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                clean_line = line.strip()
                if len(clean_line) > 5 and len(clean_line) < 100:
                    return "", f"üìù {clean_line}"
        
        # 6. –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        return "", "‚ùå –ö–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

    async def save_results_to_database(
        self, 
        results: List[CandidateResult], 
        job_description: str, 
        vacancy_title: str,
        request_id: str
    ) -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ PostgreSQL –ë–î"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ë–î
            candidates_data = []
            
            for result in results:
                # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–∫–ª—é—á–µ–Ω–∏—è –ø–æ –æ—Ü–µ–Ω–∫–µ
                def _conclusion(score: int) -> str:
                    if score >= 8:
                        return "–í—ã—Å–æ–∫–∞—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"
                    if score >= 5:
                        return "–°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"
                    return "–ù–∏–∑–∫–∞—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"
                
                candidates_data.append({
                    "candidateId": result.candidate_id,
                    "candidateName": result.name,
                    "email": result.email,
                    "preferredContact": result.preferred_contact,
                    "cvText": result.cv_text,
                    "score": result.score,
                    "reasoning": result.reasoning,
                    "suitabilityConclusion": _conclusion(result.score),
                    "questionsForApplicant": result.interview_questions,
                    "keyStrengths": result.key_strengths,
                    "concerns": result.concerns,
                    "cvSummary": result.cv_summary
                })
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
            success = await self.db_client.save_cv_analysis_results(
                request_id, vacancy_title, job_description, candidates_data
            )
            
            if success:
                # –ü–æ–∫–∞–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                stats = await self.db_client.get_request_statistics(request_id)
                if stats:
                    st.info(f"""
                    üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –ë–î:**
                    - –ö–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stats['analyzed_candidates']}
                    - –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {stats['avg_cv_score']:.1f}/10
                    - –í—ã—Å–æ–∫–∞—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å: {stats['high_suitability']}
                    - –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å: {stats['medium_suitability']}  
                    - –ù–∏–∑–∫–∞—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å: {stats['low_suitability']}
                    """)
            
            return success
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –ë–î: {str(e)}")
            return False

    def publish_to_kafka(self, items_json: list) -> None:
        if not self.kafka_producer or not self.kafka_topic:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –ª–µ–Ω–∏–≤–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ
            if not self._ensure_kafka_connected_with_retries():
                return
        try:
            self.kafka_producer.send(self.kafka_topic, items_json)
            self.kafka_producer.flush(timeout=5)
        except (KafkaError, Exception) as e:
            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–æ–≤–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ–¥—å—é—Å–µ—Ä –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
            self.kafka_producer = None
            if self._ensure_kafka_connected_with_retries():
                try:
                    self.kafka_producer.send(self.kafka_topic, items_json)
                    self.kafka_producer.flush(timeout=5)
                    return
                except Exception:
                    pass
            st.warning(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Kafka: {e}")

def main():
    st.set_page_config(
        page_title="HR Auto System - –≠—Ç–∞–ø 1 –∏–∑ 4: –ê–Ω–∞–ª–∏–∑ CV",
        page_icon="",
        layout="wide"
    )
    st.title("HR Auto System - –≠—Ç–∞–ø 1: –ê–Ω–∞–ª–∏–∑ CV")
    st.caption("–≠—Ç–∞–ø 1 –∏–∑ 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ ‚Üí –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å—Ç—Ä–µ—á ‚Üí –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ ‚Üí –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è")
    st.markdown("---")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º/–ø–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –î–û –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Å–∞–π–¥–±–∞—Ä–∞,
    # —á—Ç–æ–±—ã –º–µ—Ç–∫–∏ –º–æ–¥–µ–ª–µ–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if 'analyzer' not in st.session_state:
        try:
            st.session_state.analyzer = StreamlitCVAnalyzer()
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: {e}")
            return
    else:
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å
        try:
            env_model = os.getenv("OCR_OPENROUTER_MODEL", "meta-llama/llama-3.2-11b-vision-instruct:free")
            if getattr(st.session_state.analyzer, 'ocr_openrouter_model', None) != env_model:
                st.session_state.analyzer = StreamlitCVAnalyzer()
        except Exception:
            st.session_state.analyzer = StreamlitCVAnalyzer()

    with st.sidebar:
        st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        st.subheader("–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏")
        ocr_is_or = os.getenv("OCR_PROVIDER", "api").lower() == "openrouter"
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —É –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è, —á—Ç–æ–±—ã —Å—Ä–∞–∑—É –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∞—Å—å –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
        env_ocr_model = os.getenv("OCR_OPENROUTER_MODEL", "meta-llama/llama-3.2-11b-vision-instruct:free")
        try:
            analyzer_model = getattr(st.session_state.get('analyzer', None), 'ocr_openrouter_model', None)
        except Exception:
            analyzer_model = None
        current_ocr_model = env_ocr_model or analyzer_model or "meta-llama/llama-3.2-11b-vision-instruct:free"
        ocr_label = f"OpenRouter {current_ocr_model}" if ocr_is_or else "OCR API"
        st.text(f"OCR: {ocr_label}")
        st.text(f"–ê–Ω–∞–ª–∏–∑: {os.getenv('OPENROUTER_LLM_MODEL', 'google/gemma-3-27b-it:free')}")
        st.markdown("---")

        if 'results' in st.session_state and st.session_state.results:
            st.subheader("–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            if st.button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)"):
                results_json = json.dumps([
                    {
                        'candidate_id': r.candidate_id,  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –ë–î
                        'vacancy_title': st.session_state.get('vacancy_title', ''),  # –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏
                        'name': r.name,
                        'filename': r.filename,
                        'score': r.score,
                        'reasoning': r.reasoning,
                        'key_strengths': r.key_strengths,
                        'concerns': r.concerns,
                        'cv_summary': r.cv_summary,
                        'interview_questions': r.interview_questions,
                        'email': r.email,
                        'preferred_contact': r.preferred_contact
                    } for r in st.session_state.results
                ], ensure_ascii=False, indent=2)
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å JSON",
                    data=results_json,
                    file_name=f"cv_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json"
                )
    
    
    col1, col2 = st.columns([1, 1])
    with col1:
        st.header("–û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
        
        # –ü–æ–ª–µ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ (–¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –±–ª–æ–∫–∞)
        vacancy_title = st.text_input(
            "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏:",
            placeholder="Senior Python Developer",
            help="–£–∫–∞–∂–∏—Ç–µ —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è"
        )
        
        job_description = st.text_area(
            "–í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É:",
            height=260,
            placeholder="""–ü—Ä–∏–º–µ—Ä:
–¢—Ä–µ–±—É–µ—Ç—Å—è Senior Python Developer –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º.
–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å Python 5+ –ª–µ—Ç
- –ó–Ω–∞–Ω–∏–µ Django/FastAPI
- –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö (PostgreSQL, Redis)
- –ó–Ω–∞–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–∞–Ω–Ω—ã—Ö
–ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ:
- –û–ø—ã—Ç –≤ —Ñ–∏–Ω—Ç–µ—Ö
- –ó–Ω–∞–Ω–∏–µ Kubernetes –∏ Docker
- –û–ø—ã—Ç —Å –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏
–£—Å–ª–æ–≤–∏—è:
- –ó–∞—Ä–ø–ª–∞—Ç–∞ –æ—Ç 300,000 —Ä—É–±
- –£–¥–∞–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞
- –û—Ñ–∏—Å –≤ —Ü–µ–Ω—Ç—Ä–µ –ú–æ—Å–∫–≤—ã""",
            help="–û–ø–∏—à–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏, —É—Å–ª–æ–≤–∏—è —Ä–∞–±–æ—Ç—ã"
        )
    
    with col2:
        st.header("–ó–∞–≥—Ä—É–∑–∫–∞ CV")
        uploaded_files = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª—ã CV (PDF):",
            type=['pdf'],
            accept_multiple_files=True,
            help="–ú–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ",
            key="file_uploader"
        )
        
        if uploaded_files:
            current_file_names = [f.name for f in uploaded_files]
            if 'previous_files' not in st.session_state:
                st.session_state.previous_files = []
            if set(current_file_names) != set(st.session_state.previous_files):
                st.session_state.previous_files = current_file_names
                if 'results' in st.session_state:
                    del st.session_state.results
                if 'job_description' in st.session_state:
                    del st.session_state.job_description
                if 'vacancy_title' in st.session_state:
                    del st.session_state.vacancy_title
            
            st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(uploaded_files)}")
            for file in uploaded_files:
                st.text(f"{file.name} ({file.size / 1024:.1f} KB)")
        else:
            if 'previous_files' in st.session_state:
                st.session_state.previous_files = []
            if 'results' in st.session_state:
                del st.session_state.results
            if 'job_description' in st.session_state:
                del st.session_state.job_description
            if 'vacancy_title' in st.session_state:
                del st.session_state.vacancy_title
    
    st.markdown("---")
    can_analyze = vacancy_title.strip() and job_description and uploaded_files
    analysis_needed = True
    
    if ('results' in st.session_state and 
        'job_description' in st.session_state and
        'vacancy_title' in st.session_state and
        st.session_state.job_description == job_description and
        st.session_state.vacancy_title == vacancy_title and
        uploaded_files and
        set([f.name for f in uploaded_files]) == set(st.session_state.previous_files)):
        analysis_needed = False
    
    if analysis_needed:
        button_text = "–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑"
        button_help = "–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ CV"
    else:
        button_text = "–ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑"
        button_help = "–ü–æ–≤—Ç–æ—Ä–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ –∂–µ —Ñ–∞–π–ª—ã"
    
    if st.button(button_text, type="primary", disabled=not can_analyze, help=button_help):
        if not vacancy_title.strip():
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
        elif not job_description.strip():
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
        elif not uploaded_files:
            st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã CV")
        else:
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º CV..."):
                try:
                    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞ –∞–Ω–∞–ª–∏–∑–∞
                    st.session_state.request_id = uuid.uuid4().hex
                    results = asyncio.run(
                        st.session_state.analyzer.process_uploaded_files(uploaded_files, job_description)
                    )
                    st.session_state.results = results
                    st.session_state.job_description = job_description
                    st.session_state.vacancy_title = vacancy_title
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–î
                    try:
                        db_saved = asyncio.run(
                            st.session_state.analyzer.save_results_to_database(
                                results, job_description, vacancy_title, st.session_state.request_id
                            )
                        )
                        if db_saved:
                            st.success(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(results)}. –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î.")
                        else:
                            st.success(f"‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(results)}. –ë–î –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
                    except Exception as e:
                        st.warning(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(results)}. –û—à–∏–±–∫–∞ –ë–î: {e}")
                        st.success(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(results)}")
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
    
    if ('results' in st.session_state and st.session_state.results and
        'previous_files' in st.session_state and uploaded_files and
        set([f.name for f in uploaded_files]) == set(st.session_state.previous_files)):
        st.markdown("---")
        st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
        results = sorted(st.session_state.results, key=lambda x: x.score, reverse=True)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("–í—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", len(results))
        with col2:
            high_score = len([r for r in results if r.score >= 8])
            st.metric("–û—Ç–ª–∏—á–Ω—ã–µ (8-10)", high_score)
        with col3:
            medium_score = len([r for r in results if 5 <= r.score < 8])
            st.metric("–•–æ—Ä–æ—à–∏–µ (5-7)", medium_score)
        with col4:
            low_score = len([r for r in results if r.score < 5])
            st.metric("–°–ª–∞–±—ã–µ (1-4)", low_score)
        
        for i, result in enumerate(results):
            with st.expander(f"{result.name} - –û—Ü–µ–Ω–∫–∞: {result.score}/10", expanded=i < 3):
                col1, col2 = st.columns([2, 1])
                with col1:
                    st.subheader("–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏")
                    st.write(result.reasoning)
                    st.subheader("–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞")
                    for strength in result.key_strengths:
                        st.write(f"{strength}")
                    if result.concerns:
                        st.subheader("–ó–∞–º–µ—á–∞–Ω–∏—è")
                        for concern in result.concerns:
                            st.write(f"{concern}")
                with col2:
                    score_color = "green" if result.score >= 8 else "orange" if result.score >= 5 else "red"
                    st.metric("–û—Ü–µ–Ω–∫–∞", f"{result.score}/10")
                    st.info(f"–§–∞–π–ª: {result.filename}")
                    
                    # ID –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
                    st.caption(f"üÜî ID: {result.candidate_id}")
                    
                    # –ù–æ–≤–æ–µ –ø–æ–ª–µ: –°–ø–æ—Å–æ–± —Å–≤—è–∑–∏
                    st.subheader("–°–ø–æ—Å–æ–± —Å–≤—è–∑–∏")
                    st.write(result.preferred_contact)
                    
                    if result.cv_summary:
                        st.subheader("–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ")
                        st.write(result.cv_summary)
                
                # –ù–æ–≤–∞—è —Å–µ–∫—Ü–∏—è: –í–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
                if result.interview_questions:
                    st.markdown("---")
                    st.subheader("–í–æ–ø—Ä–æ—Å—ã –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è")
                    st.caption("–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ:")
                    for idx, question in enumerate(result.interview_questions, 1):
                        st.write(f"**{idx}.** {question}")
                    
                    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
                    questions_text = "\n".join([f"{idx}. {q}" for idx, q in enumerate(result.interview_questions, 1)])
                    if st.button(f"–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è {result.name}", key=f"copy_questions_{result.filename}"):
                        st.code(questions_text, language="text")
                        st.success("–í–æ–ø—Ä–æ—Å—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è!")

        # –°—Ç—Ä–æ–≥–∏–π JSON –¥–ª—è n8n
        try:
            vacancy_text = st.session_state.get("job_description", "")
            vacancy_title_text = st.session_state.get("vacancy_title", "")
            request_id = st.session_state.get("request_id") or uuid.uuid4().hex
            def _conclusion(score: int) -> str:
                if score >= 8:
                    return "–í—ã—Å–æ–∫–∞—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"
                if score >= 5:
                    return "–°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"
                return "–ù–∏–∑–∫–∞—è –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"

            n8n_items = [
                {
                    "candidateId": r.candidate_id,  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è –ë–î
                    "requestId": request_id,        # ID —Å–µ—Å—Å–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
                    "vacancyTitle": vacancy_title_text,  # üÜï –ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –±–ª–æ–∫–∞
                    "vacancy": vacancy_text,
                    "candidateName": r.name,
                    "cvText": r.cv_text,
                    "suitabilityConclusion": _conclusion(r.score),
                    "score": r.score,
                    "email": r.email,
                    "preferredContact": r.preferred_contact,
                    "questionsForApplicant": r.interview_questions,
                }
                for r in results
            ]
            st.markdown("---")
            st.subheader("JSON –¥–ª—è n8n")
            st.code(json.dumps(n8n_items, ensure_ascii=False, indent=2), language="json")

            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Kafka (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞)
            st.session_state.analyzer.publish_to_kafka(n8n_items)
        except Exception as _e:
            st.error(f"–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è JSON –¥–ª—è n8n: {_e}")

if __name__ == "__main__":
    main()
services:
  asr-triton:
    image: nvcr.io/nvidia/tritonserver:25.07-py3
    ports:
      - "18000:8000"
      - "18001:8001"
      - "18002:8002"
    volumes:
      - ./onnx-asr/triton_model_repository:/models:ro
    command: >
      tritonserver
      --model-repository=/models
      --strict-model-config=false
      --log-verbose=1
      --allow-http=true
      --allow-grpc=true
      --allow-metrics=true
      --backend-config=onnxruntime,enable-cpu-optimization=true
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s


  tts-api:
    build: ./vosk-tts
    ports:
      - "18200:8080"
    environment:
      - TTS__TRITON_URL=localhost:8000
      - LOG_LEVEL=INFO
      - TTS_CLI_ONLY=0
    depends_on: []
    volumes:
      - ./vosk-tts/output:/app/output
      - ./vosk-tts/logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  ui:
    build: ./ui
    ports:
      - "7860:7860"
    environment:
      - ASR_TRITON_URL=asr-triton:8000
      - TTS_TRITON_URL=localhost:8000
      - TTS_API_URL=http://tts-api:8080
      - ONNX_ASR_SRC=/app/onnx_asr_src
      - OPENROUTER_API_KEY=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
    depends_on:
      - asr-triton
      - tts-api
    volumes:
      - ./onnx-asr/src:/app/onnx_asr_src:ro
      - ./onnx-asr/v2_vocab.txt:/app/onnx_asr_vocab/v2_vocab.txt:ro


